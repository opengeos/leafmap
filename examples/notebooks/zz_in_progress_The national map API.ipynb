{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c2a17f-abb0-4bd5-b313-0f3fa4b5849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def github_raw_url(url):\n",
    "    \"\"\"Get the raw URL for a GitHub file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The GitHub URL.\n",
    "    Returns:\n",
    "        str: The raw URL.\n",
    "    \"\"\"\n",
    "    if isinstance(url, str) and url.startswith(\"https://github.com/\") and \"blob\" in url:\n",
    "        url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\n",
    "            \"blob/\", \"\"\n",
    "        )\n",
    "    return url\n",
    "\n",
    "def download_file(\n",
    "    url=None,\n",
    "    output=None,\n",
    "    quiet=False,\n",
    "    proxy=None,\n",
    "    speed=None,\n",
    "    use_cookies=True,\n",
    "    verify=True,\n",
    "    id=None,\n",
    "    fuzzy=False,\n",
    "    resume=False,\n",
    "    unzip=True,\n",
    "    overwrite=False,\n",
    "):\n",
    "    \"\"\"Download a file from URL, including Google Drive shared URL.\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): Google Drive URL is also supported. Defaults to None.\n",
    "        output (str, optional): Output filename. Default is basename of URL.\n",
    "        quiet (bool, optional): Suppress terminal output. Default is False.\n",
    "        proxy (str, optional): Proxy. Defaults to None.\n",
    "        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n",
    "        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n",
    "        verify (bool | str, optional): Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.\n",
    "        id (str, optional): Google Drive's file ID. Defaults to None.\n",
    "        fuzzy (bool, optional): Fuzzy extraction of Google Drive's file Id. Defaults to False.\n",
    "        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n",
    "        unzip (bool, optional): Unzip the file. Defaults to True.\n",
    "        overwrite (bool, optional): Overwrite the file if it already exists. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The output file path.\n",
    "    \"\"\"\n",
    "\n",
    "    import gdown\n",
    "\n",
    "    if output is None:\n",
    "        if isinstance(url, str) and url.startswith(\"http\"):\n",
    "            output = os.path.basename(url)\n",
    "\n",
    "    if isinstance(url, str):\n",
    "        if os.path.exists(os.path.abspath(output)) and (not overwrite):\n",
    "            print(\n",
    "                f\"{output} already exists. Skip downloading. Set overwrite=True to overwrite.\"\n",
    "            )\n",
    "            return os.path.abspath(output)\n",
    "        else:\n",
    "            url = github_raw_url(url)\n",
    "\n",
    "    if \"https://drive.google.com/file/d/\" in url:\n",
    "        fuzzy = True\n",
    "\n",
    "    output = gdown.download(\n",
    "        url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume\n",
    "    )\n",
    "\n",
    "    if unzip and output.endswith(\".zip\"):\n",
    "\n",
    "        with zipfile.ZipFile(output, \"r\") as zip_ref:\n",
    "            if not quiet:\n",
    "                print(\"Extracting files...\")\n",
    "            zip_ref.extractall(os.path.dirname(output))\n",
    "\n",
    "    return os.path.abspath(output)\n",
    "\n",
    "class The_national_map_USGS():\n",
    "    \"\"\"\n",
    "    The national map is a collection of topological datasets, maintained by the USGS. \n",
    "\n",
    "    It provides an API endpoint which can be used to find downloadable links for the products offered.\n",
    "        - Full description of datasets available can retrieved.\n",
    "          This consists of metadata such as detail description and publication dates.\n",
    "        - A wide range of dataformats are availble\n",
    "\n",
    "    More complete documentation for the API can be found at\n",
    "        https://apps.nationalmap.gov/tnmaccess/#/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.api_endpoint = r'https://tnmaccess.nationalmap.gov/api/v1/'\n",
    "        self.DS = self.datasets_full()\n",
    "    \n",
    "    def datasets_full(self) -> list:\n",
    "        \"\"\"\n",
    "        Full description of datasets provided.\n",
    "        Returns a JSON or empty list.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return requests.get(f'{self.api_endpoint}datasets?').json()\n",
    "        except Exception:\n",
    "            print('Failed to load metadata from The National Map API endpoint V1')\n",
    "            return []\n",
    "\n",
    "    @property\n",
    "    def prodFormats(self) -> list:\n",
    "        \"\"\"\n",
    "        Return all datatypes available in any of the collections. \n",
    "        Note that \"All\" is only peculiar to one dataset. \n",
    "        \"\"\"\n",
    "        return set(i['displayName'] for ds in self.DS for i in ds['formats'])\n",
    "\n",
    "    @property\n",
    "    def datasets(self) -> list:\n",
    "        \"\"\"\n",
    "        Returns a list of dataset tags (most common human readable self description for specific datasets).\n",
    "        \"\"\"\n",
    "        return set(y['sbDatasetTag'] for x in self.DS for y in x['tags'])\n",
    "\n",
    "    def parse_region(region, geopandas_args={}):\n",
    "        \"\"\"\n",
    "        Translate a Vector dataset to a polygon.\n",
    "\n",
    "        Args:\n",
    "            region (str | list): an URL|filepath to a vector dataset to a polygon\n",
    "            geopandas_reader_args (dict, optional): A dictionary of arguments to pass to the geopandas.read_file() function. \n",
    "                Used for reading a region URL|filepath.\n",
    "        \"\"\"\n",
    "        import geopandas as gpd\n",
    "\n",
    "        if isinstance(region, str):\n",
    "            if region.startswith(\"http\"):\n",
    "                region = github_raw_url(region)\n",
    "                region = download_file(region)\n",
    "            elif not os.path.exists(region):\n",
    "                raise ValueError(\"region must be a path or a URL to a vector dataset.\")\n",
    "\n",
    "            roi = gpd.read_file(region, **geopandas_args)\n",
    "            roi = roi.to_crs(epsg=4326)\n",
    "        return roi.total_bounds\n",
    "        \n",
    "    def download_tiles(self, region=None, out_dir=None, download_args={}, geopandas_args={}, API={'max':10}):\n",
    "        \"\"\"\n",
    "        Download the US National Elevation Datasets (NED) for a region.\n",
    "\n",
    "        Args:\n",
    "            region (str | list, optional): An URL|filepath to a vector dataset Or a list of bounds in the form of [minx, miny, maxx, maxy].\n",
    "                Alternatively you could use API parameters such as polygon or bbox.\n",
    "            out_dir (str, optional): The directory to download the files to. Defaults to None, which uses the current working directory.\n",
    "            download_args (dict, optional): A dictionary of arguments to pass to the download_file function. Defaults to {}.\n",
    "            geopandas_args (dict, optional): A dictionary of arguments to pass to the geopandas.read_file() function. \n",
    "                Used for reading a region URL|filepath.\n",
    "            API (dict, optional): A dictionary of arguments to pass to the self.find_details() function. \n",
    "                Exposes most of the documented API.\n",
    "                Defaults to {'max':10} to avoid accidental large downloads.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if out_dir is None:\n",
    "            out_dir = os.getcwd()\n",
    "        else:\n",
    "            out_dir = os.path.abspath(out_dir)\n",
    "        \n",
    "        tiles = self.find_tiles(region, return_type='list', geopandas_args=geopandas_args, API=API)\n",
    "        T = len(tiles)\n",
    "        errors = 0\n",
    "        done = 0\n",
    "\n",
    "        for i, link in enumerate(tiles):\n",
    "            file_name = os.path.basename(link)\n",
    "            out_name = os.path.join(out_dir, file_name)\n",
    "            if i<5 or (i<50 and not(i%5)) or not(i%20):\n",
    "                print(f\"Downloading {i+1} of {T}: {file_name}\")\n",
    "            try:\n",
    "                download_file(link, out_name, **download_args)\n",
    "                done += 1\n",
    "            except KeyboardInterrupt:\n",
    "                print('Cancelled download')\n",
    "                break\n",
    "            except Exception:     \n",
    "                errors += 1           \n",
    "                print(f\"Failed to download {i+1} of {T}: {file_name}\")\n",
    "                \n",
    "        print(f\"{done} Downloads completed, {errors} downloads failed\")\n",
    "        return \n",
    "\n",
    "\n",
    "    def find_tiles(self, region=None, return_type='list', geopandas_args={}, API={}):\n",
    "        \"\"\"\n",
    "        Download the US National Elevation Datasets (NED) for a region.\n",
    "\n",
    "        Args:\n",
    "            region (str | list, optional): An URL|filepath to a vector dataset Or a list of bounds in the form of [minx, miny, maxx, maxy].\n",
    "                Alternatively you could use API parameters such as polygon or bbox.\n",
    "            out_dir (str, optional): The directory to download the files to. Defaults to None, which uses the current working directory.\n",
    "            return_type (str): list | dict. Defaults to list. Changes the return output type and content.\n",
    "            geopandas_args (dict, optional): A dictionary of arguments to pass to the geopandas.read_file() function. \n",
    "                Used for reading a region URL|filepath.\n",
    "            API (dict, optional): A dictionary of arguments to pass to the self.find_details() function. \n",
    "                Exposes most of the documented API parameters. Defaults to {}.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of download_urls to the found tiles. \n",
    "            dict: A dictionary containing the metadata of the found tiles.\n",
    "        \"\"\"\n",
    "        assert region or API, 'Provide a region or use the API'\n",
    "\n",
    "        if isinstance(region,str):\n",
    "            API['polygon'] = self.parse_region(region, geopandas_args)\n",
    "        if isinstance(region, list):\n",
    "            API['bbox'] = region\n",
    "\n",
    "        results = self.find_details(**API)\n",
    "        if return_type == 'list':\n",
    "            return [i[\"downloadURL\"] for i in results.get('items')]\n",
    "        return results\n",
    "\n",
    "    def find_details(self, \n",
    "                   bbox:list[float] = None, \n",
    "                   polygon:list[tuple[float,float]] = None, \n",
    "                   datasets:list[str] | str = [], \n",
    "                   prodFormats:list[str] | str = [],\n",
    "                   prodExtents:list[str] | str = [], \n",
    "                   q:str = None, \n",
    "                   dateType:str = None, \n",
    "                   start:str = None, \n",
    "                   end:str = None, \n",
    "                   offset:int = 0, \n",
    "                   max:int = None, \n",
    "                   outputFormat:str = 'JSON', \n",
    "                   polyType:str = None, \n",
    "                   polyCode:str = None, \n",
    "                   extentQuery:int = None) -> dict:\n",
    "        \"\"\"\n",
    "        Possible search parameters (kwargs) support by API\n",
    "\n",
    "        Parameter               Values                      \n",
    "            Description\n",
    "        ---------------------------------------------------------------------------------------------------    \n",
    "        bbox                    'minx, miny, maxx, maxy'\n",
    "            Geographic longitude/latitude values expressed in  decimal degrees in a comma-delimited list.\n",
    "        polygon                 '[x,y x,y x,y x,y x,y]'       \n",
    "            Polygon, longitude/latitude values expressed in decimal degrees in a space-delimited list.\n",
    "        datasets                See: Datasets (Optional)       \n",
    "            Comma-delimited list of valid dataset tag names (sbDatasetTag)\n",
    "            From https://apps.nationalmap.gov/tnmaccess/#/product\n",
    "        prodFormats             See: Product Formats (Optional)\n",
    "            Comma-delimited list of dataset-specific formats\n",
    "            From https://apps.nationalmap.gov/tnmaccess/#/product\n",
    "        prodExtents             See: Product Extents (Optional)\n",
    "            Comma-delimited list of dataset-specific extents\n",
    "            From https://apps.nationalmap.gov/tnmaccess/#/product\n",
    "        q                       free text \n",
    "            Text input which can be used to filter by product titles and text descriptions.\n",
    "        dateType                dateCreated | lastUpdated | Publication \n",
    "            Type of date to search by.\n",
    "        start                   'YYYY-MM-DD' \n",
    "            Start date\n",
    "        end                     'YYYY-MM-DD' \n",
    "            End date (required if start date is provided)\n",
    "        offset                  integer \n",
    "            Offset into paginated results - default=0\n",
    "        max                     integer \n",
    "            Number of results returned\n",
    "        outputFormat            JSON | CSV | pjson\n",
    "            Default=JSON\n",
    "        polyType                state | huc2 | huc4 | huc8 \n",
    "            Well Known Polygon Type. Use this parameter to deliver data by state or HUC\n",
    "            (hydrologic unit codes defined by the Watershed Boundary Dataset/WBD)\n",
    "        polyCode                state FIPS code or huc number \n",
    "            Well Known Polygon Code. This value needs to coordinate with the polyType parameter.\n",
    "        extentQuery             integer \n",
    "            A Polygon code in the science base system, typically from an uploaded shapefile\n",
    "        \"\"\"\n",
    "       \n",
    "        # call locals before creating new locals\n",
    "        used_locals = {k:v for k,v in locals().items() if v and k != 'self'}\n",
    "\n",
    "        # Parsing\n",
    "    \n",
    "        def convert_polygon(x):\n",
    "            return ','.join(' '.join(map(str,point)) for point in x)\n",
    "        if polygon:\n",
    "            used_locals['polygon'] = convert_polygon(polygon)        \n",
    "        \n",
    "        # Fetch list seems broken in API ???, only takes list with 1 item or str.\n",
    "        # Looks like list is evaluated as AND instead of OR.\n",
    "\n",
    "        assert set(datasets).issubset(self.datasets) or datasets in self.datasets, f'Unknown datasets, must be elements of {self.datasets}'\n",
    "        assert set(prodFormats).issubset(self.prodFormats) or prodFormats in self.prodFormats, f'Unknown prodFormats, must be element of {self.prodFormats}'\n",
    "\n",
    "        # Validations handled better (f.e. psjon) by API endpoint error responses\n",
    "        # 'JSON', 'CSV' (misses pjson)\n",
    "        # 'dateCreated', 'lastUpdated', 'Publication'\n",
    "        # start or end or dateType / YYYY-MM-DD\n",
    "            \n",
    "        # Fetch response\n",
    "\n",
    "        response = requests.get(f'{self.api_endpoint}products?', params=used_locals)\n",
    "        if response.status_code//100 == 2:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(response.json())\n",
    "        return {}\n",
    "\n",
    "def download_tnm(region=None, out_dir=None, download_args={}, geopandas_args={}, API={}):\n",
    "    \"\"\"\n",
    "    Download the US National Elevation Datasets (NED) for a region.\n",
    "\n",
    "    Args:\n",
    "        region (str | list, optional): An URL|filepath to a vector dataset Or a list of bounds in the form of [minx, miny, maxx, maxy].\n",
    "            Alternatively you could use API parameters such as polygon or bbox.\n",
    "        out_dir (str, optional): The directory to download the files to. Defaults to None, which uses the current working directory.\n",
    "        download_args (dict, optional): A dictionary of arguments to pass to the download_file function. Defaults to {}.\n",
    "        geopandas_args (dict, optional): A dictionary of arguments to pass to the geopandas.read_file() function. \n",
    "            Used for reading a region URL|filepath.\n",
    "        API (dict, optional): A dictionary of arguments to pass to the The_national_map_USGS.find_details() function. \n",
    "            Exposes most of the documented API.\n",
    "            Defaults to {'max':10}\n",
    "            Using API={'q':'NED'} yields similar results to download_ned\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"    \n",
    "    assert region or API, 'Provide a region or use the API' \n",
    "    TNM = The_national_map_USGS()\n",
    "    if not(API.get('max')):\n",
    "        API['max'] = 10\n",
    "    return TNM.download_tiles(region, out_dir, download_args, geopandas_args, API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a869a18d-8651-49b4-865d-83bfe0b635d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tnmaccess.nationalmap.gov/api/v1/datasets?\n"
     ]
    }
   ],
   "source": [
    "U = The_national_map_USGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afc78c2-e8bb-4daa-932d-8ca9417276c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'USGS 1 Arc Second n47w069 20210611',\n",
       " 'moreInfo': 'This tile of the 3D Elevation Program (3DEP) seamless products is 1 Arc Second resolution. 3DEP data serve as the elevation layer of The National Map, and provide basic elevation information for Earth science studies and mapping applications in the United States. Scientists and resource managers use 3DEP data for global change research, hydrologic modeling, resource monitoring, mapping and visualization, and many other applications. 3DEP data compose an elevation dataset that consists of seamless layers and a high resolution layer. Each of these layers consists of the best available raster elevation data of the conterminous United States, Alaska, Hawaii, territorial islands, Mexico and Canada. 3DEP data are updated continually as new [...]',\n",
       " 'sourceId': '60d2c049d34e8409865288fc',\n",
       " 'sourceName': 'ScienceBase',\n",
       " 'sourceOriginId': None,\n",
       " 'sourceOriginName': 'gda',\n",
       " 'metaUrl': 'https://www.sciencebase.gov/catalog/item/60d2c049d34e8409865288fc',\n",
       " 'vendorMetaUrl': 'https://prd-tnm.s3.amazonaws.com/index.html?prefix=StagedProducts/Elevation/metadata/ME_CrownofMaine_2018_A18/ME_CrownofMaine_B2_2018',\n",
       " 'publicationDate': '2021-11-16',\n",
       " 'lastUpdated': '2021-11-30T23:22:10.350-07:00',\n",
       " 'dateCreated': '2021-06-22T23:02:01.397-06:00',\n",
       " 'sizeInBytes': 54848188,\n",
       " 'extent': '1 x 1 degree',\n",
       " 'format': 'GeoTIFF',\n",
       " 'downloadURL': 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n47w069/USGS_1_n47w069_20210611.tif',\n",
       " 'downloadURLRaster': None,\n",
       " 'previewGraphicURL': 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n47w069/USGS_1_n47w069_20210611.jpg',\n",
       " 'downloadLazURL': None,\n",
       " 'urls': {'TIFF': 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n47w069/USGS_1_n47w069_20210611.tif'},\n",
       " 'datasets': [],\n",
       " 'boundingBox': {'minX': -69.00166666638285,\n",
       "  'maxX': -67.9983333330162,\n",
       "  'minY': 45.99833333311773,\n",
       "  'maxY': 47.00166666648437},\n",
       " 'bestFitIndex': 0.0,\n",
       " 'body': 'This tile of the 3D Elevation Program (3DEP) seamless products is 1 Arc Second resolution.  3DEP data serve as the elevation layer of The National Map, and provide basic elevation information for Earth science studies and mapping applications in the United States. Scientists and resource managers use 3DEP data for global change research, hydrologic modeling, resource monitoring, mapping and visualization, and many other applications. 3DEP data compose an elevation dataset that consists of seamless layers and a high resolution layer.  Each of these layers consists of the best available raster elevation data of the conterminous United States, Alaska, Hawaii, territorial islands, Mexico and Canada.  3DEP data are updated continually as new data become available. Seamless 3DEP data are derived from diverse source data that are processed to a common coordinate system and unit of vertical measure. These data are distributed in geographic coordinates in units of decimal degrees, and in conformance with the North American Datum of 1983 (NAD 83). All elevation values are in meters and, over the conterminous United States, are referenced to the North American Vertical Datum of 1988 (NAVD 88). The vertical reference will vary in other areas. Seamless 3DEP data are available nationally (except for Alaska) at resolutions of 1 arc-second (approximately 30 meters) and 1/3 arc-second (approximately 10 meters). In most of Alaska, only lower resolution source data are available. As a result, most seamless 3DEP data for Alaska are at 2 arc-second (approximately 60 meters) grid spacing. Part of Alaska is available at the 1 and 1/3 arc-second resolutions from interferometric synthetic aperture radar (ifsar) collections starting in 2010.  Plans are in place for collection of statewide ifsar in Alaska. All 3DEP products are public domain.',\n",
       " 'processingUrl': 'processingUrl',\n",
       " 'modificationInfo': '2021-12-01'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {\n",
    "         'q':'National Elevation Dataset (NED) 1/3 arc-second',\n",
    "         'polyCode': '01010002',\n",
    "         'polyType': 'huc8'\n",
    "        }\n",
    "\n",
    "U.find_details(**paras)['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3519875-5615-4dd2-9d17-294d2658e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errorMessage': \"[BadRequest] 'date type is required when start date and enddate are provided' \"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.find_details(start='2021-01-01',end='2022-01-01',q='NED',outputFormat='JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1b11f0-6d12-45eb-a2ca-5014ee88959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errorMessage': \"[BadRequest] 'Value '2022-31-01' of property end is not a valid date (YYYY-MM-DD)' \"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.find_details(start='2021-01-01',end='2022-31-01',q='NED',outputFormat='JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c778cf8-8cdb-4e57-8cf2-51f7b1bc289d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'USGS Lidar Point Cloud CO SoPlatteRiver-Lot1 2013 13TFE627477 LAS 2015',\n",
       " 'moreInfo': 'Lidar (Light detection and ranging) discrete-return point cloud data are available in the American Society for Photogrammetry and Remote Sensing (ASPRS) LAS format. The LAS format is a standardized binary format for storing 3-dimensional point cloud data and point attributes along with header information and variable length records specific to the data. Millions of data points are stored as a 3-dimensional data cloud as a series of x (longitude), y (latitude) and z (elevation) points. A few older projects in this collection are in ASCII format. Please refer to http://www.asprs.org/Committee-General/LASer-LAS-File-Format-Exchange-Activities.html for additional information.',\n",
       " 'sourceId': '5a801f46e4b00f54eb2a10dc',\n",
       " 'sourceName': 'ScienceBase',\n",
       " 'sourceOriginId': None,\n",
       " 'sourceOriginName': 'gda',\n",
       " 'metaUrl': 'https://www.sciencebase.gov/catalog/item/5a801f46e4b00f54eb2a10dc',\n",
       " 'vendorMetaUrl': 'https://thor-f5.er.usgs.gov/ngtoc/metadata/waf/elevation/lidar_point_cloud/laz/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_LAS_2015/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_13TFE627477_LAS_2015_meta.xml',\n",
       " 'publicationDate': '2015-06-22',\n",
       " 'lastUpdated': '2022-02-04T06:37:01.725-07:00',\n",
       " 'dateCreated': '2018-02-11T03:47:34.444-07:00',\n",
       " 'sizeInBytes': None,\n",
       " 'extent': 'Varies',\n",
       " 'format': 'LAZ',\n",
       " 'downloadURL': 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_LAS_2015/laz/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_13TFE627477_LAS_2015.laz',\n",
       " 'downloadURLRaster': None,\n",
       " 'previewGraphicURL': 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/LPC/browse/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_13TFE627477_LAS_2015_thumb.jpg',\n",
       " 'downloadLazURL': 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_LAS_2015/laz/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_13TFE627477_LAS_2015.laz',\n",
       " 'urls': {'LAZ': 'https://rockyweb.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_LAS_2015/laz/USGS_LPC_CO_SoPlatteRiver_Lot1_2013_13TFE627477_LAS_2015.laz'},\n",
       " 'datasets': [],\n",
       " 'boundingBox': {'minX': -103.496705935362,\n",
       "  'maxX': -103.484712074143,\n",
       "  'minY': 40.4382258600637,\n",
       "  'maxY': 40.4469402549868},\n",
       " 'bestFitIndex': 0.0,\n",
       " 'body': 'Lidar (Light detection and ranging) discrete-return point cloud data are available in the American Society for Photogrammetry and Remote Sensing (ASPRS) LAS format. The LAS format is a standardized binary format for storing 3-dimensional point cloud data and point attributes along with header information and variable length records specific to the data. Millions of data points are stored as a 3-dimensional data cloud as a series of x (longitude), y (latitude) and z (elevation) points. A few older projects in this collection are in ASCII format.  Please refer to http://www.asprs.org/Committee-General/LASer-LAS-File-Format-Exchange-Activities.html for additional information. ',\n",
       " 'processingUrl': 'processingUrl',\n",
       " 'modificationInfo': '2022-02-04'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {'prodFormats':'LAS,LAZ', \n",
    "         'datasets':['Lidar Point Cloud (LPC)'],\n",
    "         'polygon': [\n",
    "                     (-104.94262695312236, 41.52867510196275),\n",
    "                     (-102.83325195312291, 41.52867510196275),\n",
    "                     (-102.83325195312291, 40.45065268246805),\n",
    "                     (-104.94262695312236, 40.45065268246805),\n",
    "                     (-104.94262695312236, 41.52867510196275),\n",
    "                   ]\n",
    "        }\n",
    "\n",
    "U.find_details(**paras)['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0c90f8-3556-4655-b61e-7eaf6ae30721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://prd-tnm.s3.amazonaws.com/StagedProducts/NAIP/fl_2015/24080/m_2408002_ne_17_1_20150719_20160222.jp2',\n",
       " 'https://prd-tnm.s3.amazonaws.com/StagedProducts/NAIP/fl_2015/24080/m_2408002_nw_17_1_20151212_20160222.jp2',\n",
       " 'https://prd-tnm.s3.amazonaws.com/StagedProducts/NAIP/fl_2015/24080/m_2408002_se_17_1_20150719_20160222.jp2',\n",
       " 'https://prd-tnm.s3.amazonaws.com/StagedProducts/NAIP/fl_2015/24080/m_2408002_sw_17_1_20151212_20160222.jp2',\n",
       " 'https://prd-tnm.s3.amazonaws.com/StagedProducts/NAIP/fl_2015/24080/m_2408003_ne_17_1_20150719_20160222.jp2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = {'polyCode':'01010002','polyType':'huc8','q':'NED'}\n",
    "U.find_tiles(p)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a2be68-2f45-4a37-bbd0-afe039a33e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3396,\n",
       " dict_keys(['total', 'items', 'errors', 'messages', 'sciencebaseQuery', 'filteredOut']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = U.find_details(**p)\n",
    "samples['total'], samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b712457-242b-40b3-a004-c846cc63b369",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1 of 50: USGS_1_n47w069_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w069_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 2 of 50: USGS_1_n47w070_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w070_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 3 of 50: USGS_1_n48w069_20210611.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n48w069/USGS_1_n48w069_20210611.tif\n",
      "To: C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n48w069_20210611.tif\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 52.2M/52.2M [00:19<00:00, 2.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 4 of 50: USGS_1_n48w070_20210611.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n48w070/USGS_1_n48w070_20210611.tif\n",
      "To: C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n48w070_20210611.tif\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 42.6M/42.6M [00:13<00:00, 3.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 5 of 50: USGS_1_n47w069_20190930.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n47w069/USGS_1_n47w069_20190930.tif\n",
      "To: C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w069_20190930.tif\n",
      " 13%|█████████▋                                                                   | 6.82M/54.5M [00:03<00:24, 1.98MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled download\n",
      "4 Downloads completed, 0 downloads failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "U.download_tiles(API=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e7ed24-a815-4641-8833-eb5909925928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tnmaccess.nationalmap.gov/api/v1/datasets?\n",
      "Downloading 1 of 10: USGS_1_n47w069_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w069_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 2 of 10: USGS_1_n47w070_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w070_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 3 of 10: USGS_1_n48w069_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n48w069_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 4 of 10: USGS_1_n48w070_20210611.tif\n",
      "C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n48w070_20210611.tif already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "Downloading 5 of 10: USGS_1_n47w069_20190930.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/historical/n47w069/USGS_1_n47w069_20190930.tif\n",
      "To: C:\\Users\\Karel\\Repos\\leafmap\\leafmap\\examples\\notebooks\\USGS_1_n47w069_20190930.tif\n",
      "  7%|█████▏                                                                       | 3.67M/54.5M [00:02<00:40, 1.27MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled download\n",
      "4 Downloads completed, 0 downloads failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_tnm(API=p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
